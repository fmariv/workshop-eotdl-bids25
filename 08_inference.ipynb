{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained our model, we can try it and so some inference!\n",
    "\n",
    "First of all, we need to prepare the inputs. We have prepared an example asset for that.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_path = \"workshop_data/deep_globe.jpg\"\n",
    "\n",
    "img = Image.open(img_path)\n",
    "plt.imshow(img)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we reshape the image, to make it ingestable for the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "imgs = np.array(img).transpose(2, 0, 1)[np.newaxis, ...].astype(np.float32) / 255.0\n",
    "\n",
    "imgs.shape, imgs.dtype, imgs.min(), imgs.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, we load the model and run it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(model)\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "\n",
    "\n",
    "ort_inputs = {input_name: imgs}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "mask = ort_outs[0] > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize our beautiful results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Squeeze the mask to remove extra dimensions\n",
    "mask_squeezed = np.squeeze(mask)\n",
    "\n",
    "# Create a figure with 3 subplots in a row\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(20, 7))\n",
    "\n",
    "# Plot the original image\n",
    "ax1.imshow(img)\n",
    "ax1.axis(\"off\")\n",
    "ax1.set_title(\"Original Image\")\n",
    "\n",
    "# Plot the segmentation mask\n",
    "ax2.imshow(mask_squeezed, cmap=\"gray\")\n",
    "ax2.axis(\"off\")\n",
    "ax2.set_title(\"Segmentation Mask\")\n",
    "\n",
    "# Plot the image with mask overlay\n",
    "overlay = np.zeros_like(img)\n",
    "overlay[:, :, 1] = mask_squeezed * 255  # Green channel for the mask\n",
    "ax3.imshow(img)\n",
    "ax3.imshow(overlay, alpha=0.5)\n",
    "ax3.axis(\"off\")\n",
    "ax3.set_title(\"Image with Mask Overlay\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and Contribution opportunities\n",
    "\n",
    "Feel free to ask questions now (live or through Discord) and make suggestions for future improvements.\n",
    "\n",
    "- Do you struggle with the inference of your AI models? Why?\n",
    "- Which tools do you currently use for that?\n",
    "- Which features would you like to have to do the inference?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
