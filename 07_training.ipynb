{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training ML models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you have explored the repository and selected an appropriate training dataset, you can stage it and train a model. In this notebook we will show an example of how to do so using the [Deep Globe Road Extraction](https://www.eotdl.com/datasets/DeepGlobeRoadExtraction) dataset.\n",
    "\n",
    "> Remember that you can run this notebook in your cloud workspace to train a model in the cloud. If you require a GPU-powered machine, let us know though Discord and we will provide one!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to streamline the training process, we will use the [PytorchEO](https://github.com/earthpulse/pytorchEO) library. This open source library is built on top of [Pytorch](https://pytorch.org/) and [Pytorch Lightning](https://lightning.ai/) to facilitate the design, implementation, training and deployment of deep learning models for Earth Observation. It offers AI-Ready EO datasets as well as ready-to-use tasks and models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_eo.datasets import DeepGlobeRoadExtraction\n",
    "\n",
    "ds = DeepGlobeRoadExtraction(batch_size=5)\n",
    "\n",
    "ds.setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is not our goal to provide a complete tutorial on how to train a model, but rather to show how to use the EOTDL. If you want to learn more about AI and training deep neural networks, we encourage you to explore the [PytorchEO](https://github.com/earthpulse/pytorchEO) library, and even contribute with more datasets, tasks, models and wrappers. We challenge you to train a better model!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This might take a few minutes!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "replace data/train/EuroSAT-RGB/Industrial/Industrial_1743.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "ds.df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from einops import rearrange\n",
    "\n",
    "batch = next(iter(ds.train_dataloader()))\n",
    "imgs, masks = batch[\"image\"], batch[\"mask\"]\n",
    "\n",
    "imgs = rearrange(imgs, \"b c h w -> b h w c\")\n",
    "masks = masks.squeeze(1)\n",
    "\n",
    "fig = plt.figure(figsize=(10, len(imgs) * 4))\n",
    "for i, (img, mask) in enumerate(zip(imgs, masks)):\n",
    "    ax = plt.subplot(len(imgs), 3, 3 * i + 1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax = plt.subplot(len(imgs), 3, 3 * i + 2)\n",
    "    ax.imshow(mask)\n",
    "    ax.axis(\"off\")\n",
    "    ax = plt.subplot(len(imgs), 3, 3 * i + 3)\n",
    "    ax.imshow(img)\n",
    "    ax.imshow(mask, alpha=0.3)\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a entrenar un modelo U-Net con parámetros predeterminados. Puedes ver un ejemplo avanzado en [road_segmentation.py](https://github.com/earthpulse/pytorchEO/blob/main/examples/road_segmentation.py).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "from lightning.pytorch.loggers import WandbLogger\n",
    "from lightning.pytorch.callbacks import ModelCheckpoint\n",
    "from pytorch_eo.tasks import ImageSegmentation\n",
    "\n",
    "ds_trainer = DeepGlobeRoadExtraction(batch_size=8, num_workers=20, pin_memory=True)\n",
    "\n",
    "task = ImageSegmentation(num_classes=ds_trainer.num_classes)\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    # accelerator=\"cuda\",   # descomentar para usar GPU\n",
    "    accelerator=\"cpu\",\n",
    "    devices=1,\n",
    "    max_epochs=10,\n",
    "    limit_train_batches=10,  # comment this line to train on the full dataset\n",
    "    limit_val_batches=10,  # comment this line to validate on the full dataset\n",
    "    callbacks=[\n",
    "        ModelCheckpoint(\n",
    "            monitor=\"val_iou\",\n",
    "            mode=\"max\",\n",
    "            save_top_k=1,\n",
    "            dirpath=\"checkpoints\",\n",
    "            filename=\"unet-{epoch:02d}-{val_iou:.2f}\",\n",
    "        )\n",
    "    ],\n",
    ")\n",
    "\n",
    "# uncomment the following line to train the model\n",
    "# trainer.fit(task, ds_trainer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once the model is trained you can evaluate it using some test data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from einops import rearrange\n",
    "from pytorch_eo.metrics.segmentation import iou\n",
    "\n",
    "# ds = DeepGlobeRoadExtraction(batch_size=5)\n",
    "# ds.setup()\n",
    "\n",
    "batch = next(iter(ds.val_dataloader()))\n",
    "imgs, masks = batch[\"image\"], batch[\"mask\"]\n",
    "\n",
    "task.cpu()\n",
    "preds = task.predict(batch) > 0.5\n",
    "\n",
    "imgs = rearrange(imgs, \"b c h w -> b h w c\")\n",
    "masks = masks.squeeze(1)\n",
    "preds = preds.squeeze(1)\n",
    "\n",
    "fig = plt.figure(figsize=(10, len(imgs) * 4))\n",
    "for i, (img, mask, pred) in enumerate(zip(imgs, masks, preds)):\n",
    "    ax = plt.subplot(len(imgs), 3, 3 * i + 1)\n",
    "    ax.imshow(img)\n",
    "    ax.axis(\"off\")\n",
    "    ax = plt.subplot(len(imgs), 3, 3 * i + 2)\n",
    "    ax.imshow(mask)\n",
    "    ax.axis(\"off\")\n",
    "    ax = plt.subplot(len(imgs), 3, 3 * i + 3)\n",
    "    ax.imshow(pred)\n",
    "    _iou = iou(pred.unsqueeze(0), mask.unsqueeze(0))\n",
    "    ax.set_title(f\"IoU: {_iou:.2f}\")\n",
    "    ax.axis(\"off\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And export it to later ingestion to the EOTDL. You can choose your preferred export method, here we use [ONNX]().\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install onnx onnxruntime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = \"data/road-segmentation-bids2025/model.onnx\"\n",
    "\n",
    "batch = next(iter(ds.val_dataloader()))\n",
    "imgs, masks = batch[\"image\"], batch[\"mask\"]\n",
    "\n",
    "task.cpu()\n",
    "task.eval()\n",
    "\n",
    "task.to_onnx(\n",
    "    filepath,\n",
    "    imgs,\n",
    "    export_params=True,\n",
    "    input_names=[\"input\"],\n",
    "    output_names=[\"output\"],\n",
    "    dynamic_axes={\n",
    "        \"input\": {0: \"batch_size\", 2: \"height\", 3: \"width\"},\n",
    "        \"output\": {0: \"batch_size\"},\n",
    "    },\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This has been a fast and easy example on how to train an ML model with a datasets downloaded from EOTDL. Este bloque de código realiza **inferencia** utilizando el modelo en formato **ONNX** y el conjunto de imágenes como entrada.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import onnxruntime\n",
    "import numpy as np\n",
    "\n",
    "ort_session = onnxruntime.InferenceSession(filepath)\n",
    "input_name = ort_session.get_inputs()[0].name\n",
    "ort_inputs = {input_name: imgs.numpy()}\n",
    "ort_outs = ort_session.run(None, ort_inputs)\n",
    "ort_outs[0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este bloque de código configura la inferencia del modelo ONNX para que se ejecute en **GPU** (si está disponible), recorre el dataloader de validación y calcula el **IoU promedio** en tiempo real.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "providers = [\n",
    "    (\n",
    "        \"CUDAExecutionProvider\",\n",
    "        {\n",
    "            # Utiliza el dispositivo GPU actual\n",
    "            \"device_id\": torch.cuda.current_device(),\n",
    "            \"user_compute_stream\": str(torch.cuda.current_stream().cuda_stream),\n",
    "        },\n",
    "    )\n",
    "]\n",
    "sess_options = onnxruntime.SessionOptions()\n",
    "# Create the session with the options and the model file path\n",
    "ort_session = onnxruntime.InferenceSession(\n",
    "    filepath, sess_options=sess_options, providers=providers\n",
    ")\n",
    "\n",
    "ious = []\n",
    "pbar = tqdm(ds.val_dataloader())\n",
    "for batch in pbar:\n",
    "    ort_inputs = {input_name: batch[\"image\"].numpy()}\n",
    "    ort_outs = ort_session.run(None, ort_inputs)\n",
    "    ious.append(iou(torch.tensor(ort_outs[0]), batch[\"mask\"]))\n",
    "    pbar.set_description(f\"mean IoU: {np.mean(ious):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will learn how to ingest this model to EOTDL in following.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion and Contribution opportunities\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feel free to ask questions now (live or through Discord) and make suggestions for future improvements.\n",
    "\n",
    "- What would you like to see in the EOTDL concerning training?\n",
    "- What are the main challenges you face when training ML models with EO data?\n",
    "- What are the main datasets you would like to see in the EOTDL?\n",
    "- What are the main tasks you would like to see implemented?\n",
    "- What are the main models you would like to see implemented?\n",
    "- What are the frameworks you would like to have wrappers for?\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
